# 分布式训练模型保存问题修复计划

## 问题总结

在分布式训练（3个GPU）过程中，保存checkpoint时出现进程争用导致训练停止的问题。

## 根本原因

1. **主训练循环中只有rank 0保存模型**（`main_train_vrt.py:201`）
   - rank 0执行保存操作，需要较长时间
   - rank 1, 2继续执行，进入下一个训练迭代
   - 导致进程间状态不同步，DistributedDataParallel同步失败

2. **缺少分布式barrier同步点**
   - PyTorch DDP要求所有进程在训练循环中保持同步
   - 保存操作打破了这种同步

3. **保存操作非原子性**
   - 直接写入目标文件，中断可能导致文件损坏

4. **静态图特殊处理点也存在同样问题**（`main_train_vrt.py:209-212`）

## 修复方案

### 方案A: 最小侵入式修复（推荐用于快速验证）⭐

**优点**: 改动最小，风险最低，符合项目现有结构
**缺点**: 没有解决文件保存的原子性问题

**修改文件**: 
- `main_train_vrt.py`
- `utils/utils_dist.py`（添加安全的barrier函数）

**具体步骤**:

1. 在`utils/utils_dist.py`添加安全的barrier函数
2. 在`main_train_vrt.py`的保存点后添加barrier调用

### 方案B: 完整加固方案（推荐用于生产环境）⭐⭐⭐

**优点**: 解决所有潜在问题，提高系统健壮性
**缺点**: 改动较多，需要更多测试

**修改文件**:
- `utils/utils_dist.py`（添加barrier和同步工具）
- `models/model_base.py`（改进save_network和save_optimizer）
- `main_train_vrt.py`（添加barrier调用）

**具体步骤**:

1. 在`utils/utils_dist.py`添加barrier和同步辅助函数
2. 改进`models/model_base.py`的保存方法（原子性+异常处理）
3. 在`main_train_vrt.py`添加同步点
4. 可选：添加checkpoint管理功能

### 方案C: 架构重构方案（不推荐）❌

**说明**: 修改保存策略，让所有进程都保存，或使用异步保存
**原因**: 与项目现有架构差异太大，风险高

## 推荐实施计划

### 阶段1: 立即修复（方案A）

**目标**: 解决训练停止问题，让训练能够继续进行

**实施步骤**:

1. **修改 `utils/utils_dist.py`**
   - 添加 `barrier_safe()` 函数
   - 提供安全的barrier调用，避免非分布式模式报错

2. **修改 `main_train_vrt.py`**
   - 在两个保存点后添加barrier
   - 位置1: 常规checkpoint保存后（第203行后）
   - 位置2: 静态图特殊保存后（第212行后）

**预期效果**: 
- 所有进程在保存后同步，避免状态不一致
- 训练可以正常继续

**风险评估**: 低
- 只添加同步点，不修改保存逻辑
- 符合PyTorch DDP最佳实践

### 阶段2: 增强健壮性（方案B的保存部分）

**目标**: 提高保存操作的可靠性，避免文件损坏

**实施步骤**:

1. **修改 `models/model_base.py`**
   - 改进 `save_network()`: 使用临时文件+原子重命名
   - 改进 `save_optimizer()`: 同样使用原子保存
   - 添加异常处理和日志

**预期效果**:
- 保存过程被中断时不会留下损坏文件
- 更好的错误提示

**风险评估**: 低
- 不改变外部接口，只改进内部实现
- 使用Python标准库（shutil），兼容性好

### 阶段3: 可选增强（未来优化）

**可选功能**:
1. Checkpoint版本管理（保留最近N个checkpoint）
2. 保存完整训练状态（包括scheduler、scaler等）
3. 断点续训自动恢复机制
4. 保存时间和文件大小监控

## 详细实施代码

### 1. 修改 `utils/utils_dist.py`

在文件末尾添加：

```python
def barrier_safe():
    """
    安全的barrier函数，只在分布式模式下执行同步
    用于确保所有进程在关键点（如保存checkpoint）保持同步
    """
    if not dist.is_available():
        return
    
    if not dist.is_initialized():
        return
    
    # 执行barrier，等待所有进程到达此点
    dist.barrier()
```

### 2. 修改 `main_train_vrt.py`

#### 位置1: 常规checkpoint保存（第198-203行）

```python
# 修改前:
if current_step % opt['train']['checkpoint_save'] == 0 and opt['rank'] == 0:
    logger.info('Saving the model.')
    model.save(current_step)

# 修改后:
if current_step % opt['train']['checkpoint_save'] == 0 and opt['rank'] == 0:
    logger.info('Saving the model.')
    model.save(current_step)
# 等待rank 0完成保存，避免进程间状态不一致
if current_step % opt['train']['checkpoint_save'] == 0 and opt['dist']:
    utils_dist.barrier_safe()
```

#### 位置2: 静态图特殊保存（第209-217行）

```python
# 修改前:
if opt['use_static_graph'] and (current_step == opt['train']['fix_iter'] - 1):
    current_step += 1
    model.update_learning_rate(current_step)
    model.save(current_step)
    current_step -= 1
    logger.info('Saving models ahead of time...')

# 修改后:
if opt['use_static_graph'] and (current_step == opt['train']['fix_iter'] - 1):
    current_step += 1
    model.update_learning_rate(current_step)
    if opt['rank'] == 0:
        model.save(current_step)
    # 等待rank 0完成保存
    if opt['dist']:
        utils_dist.barrier_safe()
    current_step -= 1
    logger.info('Saving models ahead of time...')
```

### 3. 修改 `models/model_base.py` (阶段2)

```python
import shutil
import tempfile

def save_network(self, save_dir, network, network_label, iter_label):
    """
    保存网络参数，使用原子性保存避免文件损坏
    """
    save_filename = '{}_{}.pth'.format(iter_label, network_label)
    save_path = os.path.join(save_dir, save_filename)
    network = self.get_bare_model(network)
    state_dict = network.state_dict()
    for key, param in state_dict.items():
        state_dict[key] = param.cpu()
    
    # 使用临时文件实现原子性保存
    tmp_save_path = save_path + '.tmp'
    try:
        torch.save(state_dict, tmp_save_path)
        # 原子性重命名（在同一文件系统上是原子操作）
        shutil.move(tmp_save_path, save_path)
    except Exception as e:
        # 清理临时文件
        if os.path.exists(tmp_save_path):
            try:
                os.remove(tmp_save_path)
            except:
                pass
        raise RuntimeError(f'Failed to save {network_label} to {save_path}: {str(e)}')

def save_optimizer(self, save_dir, optimizer, optimizer_label, iter_label):
    """
    保存优化器状态，使用原子性保存避免文件损坏
    """
    save_filename = '{}_{}.pth'.format(iter_label, optimizer_label)
    save_path = os.path.join(save_dir, save_filename)
    
    tmp_save_path = save_path + '.tmp'
    try:
        torch.save(optimizer.state_dict(), tmp_save_path)
        shutil.move(tmp_save_path, save_path)
    except Exception as e:
        if os.path.exists(tmp_save_path):
            try:
                os.remove(tmp_save_path)
            except:
                pass
        raise RuntimeError(f'Failed to save {optimizer_label} to {save_path}: {str(e)}')
```

## 验证计划

### 验证1: 基本功能验证
- [ ] 启动分布式训练（3个GPU）
- [ ] 运行到第一个checkpoint保存点
- [ ] 检查训练是否继续正常进行
- [ ] 检查保存的文件是否完整

### 验证2: 进程同步验证
- [ ] 在日志中添加时间戳，确认所有进程在保存点同步
- [ ] 使用 `nvidia-smi` 监控GPU利用率，确认保存时所有GPU都暂停

### 验证3: 鲁棒性验证
- [ ] 在保存过程中模拟中断（kill -15）
- [ ] 检查checkpoint文件是否损坏
- [ ] 使用损坏的checkpoint恢复训练，验证错误处理

### 验证4: 性能验证
- [ ] 对比修改前后的训练速度
- [ ] 确认barrier不会引入显著的性能损失

## 回滚计划

如果出现问题，可以快速回滚：

1. **阶段1回滚**: 注释掉添加的 `barrier_safe()` 调用
2. **阶段2回滚**: 恢复原始的 `save_network()` 和 `save_optimizer()` 方法
3. 保留修改前的备份: `git stash` 或手动备份

## 影响范围评估

### 受影响的文件
- `main_train_vrt.py` (训练主循环)
- `utils/utils_dist.py` (分布式工具)
- `models/model_base.py` (模型基类)

### 不受影响的部分
- 模型架构定义 (`models/network_vrt.py`)
- 数据加载 (`data/`)
- 配置文件 (`options/`)
- 其他训练脚本 (需要后续应用相同修复)

## 后续工作

1. **应用到其他训练脚本**
   - `main_train_gan.py`
   - `main_train_psnr.py`
   - `main_train_drunet.py`
   - `KAIR-master/` 目录下的对应文件

2. **文档更新**
   - 更新README，说明分布式训练的注意事项
   - 添加故障排查指南

3. **监控和告警**
   - 添加保存时间监控
   - 添加文件完整性检查

## 参考资料

- PyTorch DDP Tutorial: https://pytorch.org/tutorials/intermediate/ddp_tutorial.html
- torch.distributed.barrier: https://pytorch.org/docs/stable/distributed.html#torch.distributed.barrier
- 原子文件操作: Python shutil.move() 文档

