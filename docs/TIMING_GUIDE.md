# è®­ç»ƒè€—æ—¶å®Œæ•´æŒ‡å—

**ç»¼åˆæ–‡æ¡£** - åŒ…å«è€—æ—¶åˆ†æã€è°ƒè¯•æŒ‡å—å’Œæ—¥å¿—ç³»ç»Ÿ

---

## ğŸ“‹ ç›®å½•

1. [æ‰§è¡Œæ‘˜è¦](#æ‰§è¡Œæ‘˜è¦)
2. [è€—æ—¶åˆ†ææŠ¥å‘Š](#è€—æ—¶åˆ†ææŠ¥å‘Š)
3. [è€—æ—¶æ—¥å¿—ç³»ç»Ÿ](#è€—æ—¶æ—¥å¿—ç³»ç»Ÿ)
4. [æ€§èƒ½è°ƒè¯•æŒ‡å—](#æ€§èƒ½è°ƒè¯•æŒ‡å—)
5. [ä¼˜åŒ–å»ºè®®](#ä¼˜åŒ–å»ºè®®)

---

## ğŸš¨ æ‰§è¡Œæ‘˜è¦

### æ ¸å¿ƒå‘ç°

**ç“¶é¢ˆ100%åœ¨GPUè®¡ç®—ï¼Œæ•°æ®åŠ è½½ä¸æ˜¯é—®é¢˜ï¼**

- **æ•°æ®åŠ è½½æ—¶é—´**: 0.1ms âœ… (å®Œå…¨ä¸æ˜¯ç“¶é¢ˆ)
- **å‰å‘ä¼ æ’­æ—¶é—´**: 1855ms (31%)
- **åå‘ä¼ æ’­æ—¶é—´**: 4000-5000ms (70-83%) âš ï¸ ä¸»è¦ç“¶é¢ˆ
- **æ€»è®­ç»ƒæ—¶é—´**: ~6ç§’/æ­¥ â†’ 0.5 samples/s

### ä¸ºä»€ä¹ˆè®­ç»ƒè¿™ä¹ˆæ…¢ï¼Ÿ

1. **Gradient Checkpointingä»£ä»·** - åå‘ä¼ æ’­éœ€è¦é‡è®¡ç®—ï¼Œæ—¶é—´Ã—2.5
2. **batch_size=1ä½æ•ˆç‡** - GPUè®¡ç®—å•å…ƒå¤§é‡é—²ç½®
3. **VRTæ¨¡å‹å¤æ‚åº¦** - Stage8å ç”¨965msï¼ˆ27%ï¼‰

### å¿«é€Ÿä¼˜åŒ–æ–¹æ¡ˆ

```yaml
# æ¨èé…ç½® - é€Ÿåº¦æå‡12.6Ã—
TRAIN:
  OPTIM:
    TYPE: adamw8bit        # ä½¿ç”¨8-bit optimizer
  BATCH_SIZE: 3            # å¢å¤§batch size

MODEL:
  VRT:
    use_checkpoint_attn: false  # ç¦ç”¨checkpointing
    use_checkpoint_ffn: false
```

**é¢„æœŸæ•ˆæœ**:
- è®­ç»ƒæ—¶é—´: 88.5å°æ—¶ â†’ 7å°æ—¶
- ååé‡: 0.5 samples/s â†’ 3.6 samples/s
- æ˜¾å­˜å ç”¨: 32GB â†’ 34GB (70% of 48GB)

---

## ğŸ“Š è€—æ—¶åˆ†ææŠ¥å‘Š

### å…³é”®æ•°æ®å¯¹æ¯”

#### è®­ç»ƒæ—¥å¿—æ˜¾ç¤º
```
step 950/8880 | ... | 0.5 samples/s | data_time=0.1ms
```

#### Timingæ—¥å¿—æ˜¾ç¤ºï¼ˆå•æ­¥ï¼‰
```
å‰å‘ä¼ æ’­æ€»è€—æ—¶    : 1805.28ms (50.0%)
VRTå¤„ç†          : 1799.99ms (49.9%)
Total           : 3610.53ms
```

### æ—¶é—´åˆ†è§£åˆ†æ

| ç»„ä»¶ | è€—æ—¶ | å æ¯” |
|------|------|------|
| **å‰å‘ä¼ æ’­** | 1805 ms | 50% |
| - VRT Stage8 | 965 ms | 27% |
| - VRT Stage2 | 269 ms | 7% |
| - VRT Stage7 | 137 ms | 4% |
| - VRT Stage3 | 95 ms | 3% |
| - å…¶ä»–Stages | ~334 ms | 9% |
| **Spikeæ¨¡å—** | ~5 ms | 0.1% |
| **Total** | **3610 ms** | **100%** |

**æ³¨æ„**ï¼šè¿™åªæ˜¯å‰å‘ä¼ æ’­ï¼è¿˜ç¼ºå°‘ï¼š
- âŒ åå‘ä¼ æ’­ï¼ˆbackwardï¼‰
- âŒ æ¢¯åº¦åŒæ­¥ï¼ˆDDP allreduceï¼‰
- âŒ Optimizer step
- âŒ æ•°æ®åŠ è½½

### å®Œæ•´è®­ç»ƒæ­¥éª¤æ—¶é—´ä¼°ç®—

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          å•æ­¥è®­ç»ƒæ—¶é—´åˆ†è§£ (6ç§’)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  1. æ•°æ®åŠ è½½ï¼ˆdata loadingï¼‰                        â”‚
â”‚     - ä»DataLoaderè·å–batch                        â”‚
â”‚     - Transfer to GPU                             â”‚
â”‚     æ—¶é—´: data_time = 0.1ms âœ…                     â”‚
â”‚                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  2. å‰å‘ä¼ æ’­ï¼ˆforward passï¼‰                       â”‚
â”‚     - VRTå¤„ç†: 1800ms                             â”‚
â”‚     - Spikeæ¨¡å—: 5ms                               â”‚
â”‚     - Lossè®¡ç®—: ~50ms                              â”‚
â”‚     æ—¶é—´: ~1855ms (~31%)                           â”‚
â”‚                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  3. åå‘ä¼ æ’­ï¼ˆbackward passï¼‰                      â”‚
â”‚     - Autogradè®¡ç®—æ¢¯åº¦                             â”‚
â”‚     - Gradient checkpointingé‡è®¡ç®—                 â”‚
â”‚     - é¢„è®¡: 2-3Ã— å‰å‘æ—¶é—´                          â”‚
â”‚     æ—¶é—´: ~4000-5000ms (~70-83%)                   â”‚
â”‚                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  4. æ¢¯åº¦åŒæ­¥ï¼ˆDDP allreduceï¼‰                      â”‚
â”‚     - 3ä¸ªGPUä¹‹é—´åŒæ­¥æ¢¯åº¦                           â”‚
â”‚     - ~6GBæ¢¯åº¦æ•°æ® Ã— é€šä¿¡                          â”‚
â”‚     æ—¶é—´: ~100-200ms (~2-3%)                       â”‚
â”‚                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  5. Optimizeræ›´æ–°ï¼ˆAdam stepï¼‰                     â”‚
â”‚     - è®¡ç®—momentumå’Œvariance                       â”‚
â”‚     - æ›´æ–°~6GBå‚æ•°                                 â”‚
â”‚     æ—¶é—´: ~50-100ms (~1%)                          â”‚
â”‚                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  æ€»è®¡: ~6000ms                                     â”‚
â”‚  ååé‡: 3 samples / 6s = 0.5 samples/s âœ…         â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ç“¶é¢ˆç¡®è®¤

#### ä¸»è¦ç“¶é¢ˆï¼ˆå æ€»æ—¶é—´70-83%ï¼‰
ğŸ”´ **åå‘ä¼ æ’­** - 4000-5000ms
- Gradient checkpointingé‡è®¡ç®—
- å¤§é‡å·ç§¯å±‚æ¢¯åº¦
- VGG lossæ¢¯åº¦ä¼ æ’­

#### æ¬¡è¦ç“¶é¢ˆï¼ˆå æ€»æ—¶é—´31%ï¼‰
ğŸŸ¡ **å‰å‘ä¼ æ’­** - 1855ms
- VRT Stage8: 965msï¼ˆæœ€æ…¢çš„stageï¼‰
- VRT Stage2: 269ms
- å…¶ä»–stages: 621ms

#### éç“¶é¢ˆï¼ˆå æ€»æ—¶é—´<3%ï¼‰
ğŸŸ¢ **æ•°æ®åŠ è½½** - 0.1ms
ğŸŸ¢ **DDPåŒæ­¥** - 100-200ms
ğŸŸ¢ **Optimizer** - 50-100ms

---

## â±ï¸ è€—æ—¶æ—¥å¿—ç³»ç»Ÿ

### æ¦‚è¿°

ä¸ºäº†æ›´å¥½åœ°åˆ†æè®­ç»ƒè¿‡ç¨‹ä¸­å„ä¸ªæ¨¡å—çš„è€—æ—¶æƒ…å†µï¼Œæˆ‘ä»¬å®ç°äº†ä¸€ä¸ªç‹¬ç«‹çš„è€—æ—¶æ—¥å¿—ç³»ç»Ÿ (`TimingLogger`)ã€‚è¯¥ç³»ç»Ÿæä¾›äº†ï¼š

1. **åŸåœ°æ›´æ–°çš„ç»ˆç«¯æ˜¾ç¤º** - é¿å…ç»ˆç«¯æ—¥å¿—åˆ·å±
2. **è¯¦ç»†çš„æ–‡ä»¶æ—¥å¿—** - è®°å½•æ¯ä¸ªstepçš„å®Œæ•´è€—æ—¶åˆ†å¸ƒ
3. **å±‚æ¬¡åŒ–çš„ç»Ÿè®¡** - æ”¯æŒåµŒå¥—æ¨¡å—çš„è€—æ—¶è®°å½•
4. **å®æ—¶ç»Ÿè®¡** - æ˜¾ç¤ºå¹³å‡å€¼ã€æœ€å°å€¼ã€æœ€å¤§å€¼

### ç»ˆç«¯æ˜¾ç¤ºç¤ºä¾‹

ç»ˆç«¯æ˜¾ç¤ºé‡‡ç”¨åŸåœ°æ›´æ–°ï¼Œå±•ç¤ºtop 5è€—æ—¶æ¨¡å—çš„è¿›åº¦æ¡å’Œç™¾åˆ†æ¯”ï¼š

```
â”Œâ”€ Timing Profile (Step 42) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ å‰å‘ä¼ æ’­æ€»è€—æ—¶                   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  280.0ms 45.2%
â”‚ VRTå¤„ç†                     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  150.0ms 24.2%
â”‚ Spikeæ—¶é—´è‡ªæ³¨æ„åŠ›               â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   80.0ms 12.9%
â”‚ VRTèåˆ                     â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   60.0ms  9.7%
â”‚ Spikeç¼–ç å™¨                  â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   50.0ms  8.1%
â””â”€ Total:  620.0ms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

### æ–‡ä»¶æ—¥å¿—ç¤ºä¾‹

è¯¦ç»†æ—¥å¿—ä¼šä¿å­˜åˆ°æ–‡ä»¶ä¸­ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

```
================================================================================
Step 1
================================================================================
å‰å‘ä¼ æ’­æ€»è€—æ—¶                                 :   280.00ms ( 45.2%) [avg:   280.00ms]
VRTå¤„ç†                                   :   150.00ms ( 24.2%) [avg:   150.00ms]
  - Stage1                              :    25.00ms [avg:    25.00ms]
  - Stage2                              :    23.00ms [avg:    23.00ms]
  - Stage3                              :    22.00ms [avg:    22.00ms]
  ...
Spikeæ—¶é—´è‡ªæ³¨æ„åŠ›                             :    80.00ms ( 12.9%) [avg:    80.00ms]
  - Self-Attention                      :    50.00ms [avg:    50.00ms]
  - FFN                                 :    20.00ms [avg:    20.00ms]
  - ç»´åº¦è½¬æ¢                                :    10.00ms [avg:    10.00ms]
...
Total-----------------------------------:   620.00ms
```

### ä½¿ç”¨æ–¹æ³•

#### åœ¨è®­ç»ƒä»£ç ä¸­ä½¿ç”¨

```python
from src.utils.timing_logger import TimingLogger, set_global_timing_logger, log_timing

# åˆå§‹åŒ–logger (åœ¨mainè¿›ç¨‹ä¸­)
timing_logger = TimingLogger(
    log_dir=save_root / "logs",
    enable_console=True,
    enable_file=True,
    console_update_interval=10,  # æ¯10ä¸ªstepæ›´æ–°ä¸€æ¬¡ç»ˆç«¯æ˜¾ç¤º
    file_flush_interval=50,      # æ¯50ä¸ªstepåˆ·æ–°ä¸€æ¬¡æ–‡ä»¶
)
set_global_timing_logger(timing_logger)

# åœ¨éœ€è¦è®°å½•è€—æ—¶çš„åœ°æ–¹
log_timing("æ¨¡å—åç§°", time_in_ms)
log_timing("æ¨¡å—åç§°/å­æ¨¡å—", time_in_ms)  # æ”¯æŒå±‚æ¬¡åŒ–

# æ¯ä¸ªè®­ç»ƒstepç»“æŸæ—¶
timing_logger.step()

# è®­ç»ƒç»“æŸæ—¶
timing_logger.print_summary()
timing_logger.close()
```

#### åœ¨æ¨¡å‹ä»£ç ä¸­ä½¿ç”¨

```python
from src.utils.timing_logger import log_timing
import torch

class MyModule(nn.Module):
    def forward(self, x):
        # æ–¹æ³•1: æ‰‹åŠ¨è®¡æ—¶
        start = time.time()
        result = self.process(x)
        log_timing("MyModule/process", (time.time() - start) * 1000)
        
        # æ–¹æ³•2: ä½¿ç”¨CUDAäº‹ä»¶ï¼ˆæ›´å‡†ç¡®ï¼‰
        if torch.cuda.is_available():
            start_event = torch.cuda.Event(enable_timing=True)
            end_event = torch.cuda.Event(enable_timing=True)
            
            start_event.record()
            result = self.process(x)
            end_event.record()
            
            torch.cuda.synchronize()
            elapsed_ms = start_event.elapsed_time(end_event)
            log_timing("MyModule/process", elapsed_ms)
        
        return result
```

### é…ç½®é¡¹

åœ¨ `config.yaml` ä¸­å¯ä»¥é…ç½®ä»¥ä¸‹é€‰é¡¹ï¼š

```yaml
LOG:
  # æ˜¯å¦å¯ç”¨è€—æ—¶æ—¥å¿—
  ENABLE_TIMING_LOG: true
  
  # æ˜¯å¦åœ¨ç»ˆç«¯æ˜¾ç¤º
  TIMING_CONSOLE: true
  
  # æ˜¯å¦è®°å½•åˆ°æ–‡ä»¶
  TIMING_FILE: true
  
  # ç»ˆç«¯æ›´æ–°é—´éš”ï¼ˆæ¯Nä¸ªstepï¼‰
  TIMING_CONSOLE_INTERVAL: 10
  
  # æ–‡ä»¶åˆ·æ–°é—´éš”ï¼ˆæ¯Nä¸ªstepï¼‰
  TIMING_FILE_INTERVAL: 50
```

---

## ğŸ” æ€§èƒ½è°ƒè¯•æŒ‡å—

### æ·»åŠ çš„è°ƒè¯•åŠŸèƒ½

#### 1. ä¸»æ¨¡å‹ (VRTWithSpike)

ä½ç½®: `src/models/integrate_vrt.py`

æ‰“å°ä¿¡æ¯åŒ…æ‹¬ï¼š
- æ€»ä½“å‰å‘ä¼ æ’­æ—¶é—´
- ä¸‰ä¸ªä¸»è¦æ­¥éª¤çš„è€—æ—¶åŠå æ¯”ï¼š
  - Spikeç¼–ç å™¨
  - Spikeæ—¶é—´è‡ªæ³¨æ„åŠ›
  - VRTå¤„ç†ä¸èåˆ

#### 2. Spikeç¼–ç å™¨ (SpikeEncoder3D)

ä½ç½®: `src/models/spike_encoder3d.py`

æ‰“å°ä¿¡æ¯åŒ…æ‹¬ï¼š
- è¾“å…¥ç»´åº¦è½¬æ¢æ—¶é—´
- æ¯ä¸ªå°ºåº¦çš„å¤„ç†æ—¶é—´ï¼ˆæŠ•å½±ã€æ®‹å·®ã€ä¸‹é‡‡æ ·ï¼‰
- æ¯ä¸ªå°ºåº¦çš„è¾“å‡ºshape
- æ€»è€—æ—¶

#### 3. Spikeæ—¶é—´è‡ªæ³¨æ„åŠ› (SpikeTemporalSA)

ä½ç½®: `src/models/spike_temporal_sa.py`

æ‰“å°ä¿¡æ¯åŒ…æ‹¬ï¼š
- æ¯ä¸ªå°ºåº¦çš„å¤„ç†æ—¶é—´
- æ¯ä¸ªå°ºåº¦å†…éƒ¨çš„è¯¦ç»†è®¡æ—¶ï¼š
  - ç»´åº¦è½¬æ¢
  - Self-Attentionï¼ˆæ€»æ—¶é—´å’Œæ¯å—å¹³å‡æ—¶é—´ï¼‰
  - FFNå‰é¦ˆç½‘ç»œï¼ˆæ€»æ—¶é—´å’Œæ¯å—å¹³å‡æ—¶é—´ï¼‰
  - å—æ•°é‡ç»Ÿè®¡
- æ€»è€—æ—¶

#### 4. VRTå„é˜¶æ®µ

ä½ç½®: `src/models/integrate_vrt.py` (åœ¨monkey-patchçš„forward_featuresä¸­)

æ‰“å°ä¿¡æ¯åŒ…æ‹¬ï¼š
- ç¼–ç é˜¶æ®µï¼ˆStage 1-4ï¼‰æ¯ä¸ªstageçš„æ—¶é—´
- æ¯ä¸ªstageåçš„èåˆæ—¶é—´
- ç“¶é¢ˆå±‚ï¼ˆStage 5ï¼‰æ—¶é—´
- è§£ç é˜¶æ®µï¼ˆStage 6-7ï¼‰æ—¶é—´
- é‡å»ºå±‚ï¼ˆStage 8ï¼‰æ—¶é—´

### è°ƒè¯•è¾“å‡ºç¤ºä¾‹

```
================================================================================
å¼€å§‹å‰å‘ä¼ æ’­ - VRTWithSpike
================================================================================

[ä¸»æ¨¡å‹] æ­¥éª¤1: Spikeç¼–ç å™¨
[ä¸»æ¨¡å‹] è¾“å…¥shape - RGB: torch.Size([1, 4, 3, 256, 256]), Spike: torch.Size([1, 4, 5, 256, 256])
  [SpikeEncoder3D] è¾“å…¥ç»´åº¦è½¬æ¢: 0.15ms
  [SpikeEncoder3D] å°ºåº¦0 (è¾“å…¥æŠ•å½±+æ®‹å·®): 45.23ms, è¾“å‡ºshape: torch.Size([1, 96, 4, 256, 256])
  [SpikeEncoder3D] å°ºåº¦1 (ä¸‹é‡‡æ ·+æ®‹å·®): 38.67ms, è¾“å‡ºshape: torch.Size([1, 96, 4, 128, 128])
  [SpikeEncoder3D] å°ºåº¦2 (ä¸‹é‡‡æ ·+æ®‹å·®): 25.43ms, è¾“å‡ºshape: torch.Size([1, 96, 4, 64, 64])
  [SpikeEncoder3D] å°ºåº¦3 (ä¸‹é‡‡æ ·+æ®‹å·®): 18.92ms, è¾“å‡ºshape: torch.Size([1, 96, 4, 32, 32])
  [SpikeEncoder3D] æ€»è€—æ—¶: 128.40ms

[ä¸»æ¨¡å‹] Spikeç¼–ç å™¨æ€»è€—æ—¶: 128.40ms

[ä¸»æ¨¡å‹] æ­¥éª¤2: Spikeæ—¶é—´è‡ªæ³¨æ„åŠ›
  [SpikeTemporalSA] å¼€å§‹å¤„ç†4ä¸ªå°ºåº¦çš„ç‰¹å¾
  [SpikeTemporalSA] å°ºåº¦0: è¾“å…¥shape=torch.Size([1, 96, 4, 256, 256])
    [SpikeTemporalSelfAttention] ç»´åº¦è½¬æ¢: 0.12ms
    [SpikeTemporalSelfAttention] å¤„ç†äº†256ä¸ªå—
    [SpikeTemporalSelfAttention] Self-Attentionæ€»è€—æ—¶: 156.78ms (å¹³å‡0.61ms/å—)
    [SpikeTemporalSelfAttention] FFNæ€»è€—æ—¶: 89.34ms (å¹³å‡0.35ms/å—)
    [SpikeTemporalSelfAttention] å—å¤„ç†æ€»è€—æ—¶: 246.12ms
    [SpikeTemporalSelfAttention] æ€»è€—æ—¶: 246.24ms
  [SpikeTemporalSA] å°ºåº¦0è€—æ—¶: 246.45ms

[ä¸»æ¨¡å‹] Spikeæ—¶é—´è‡ªæ³¨æ„åŠ›æ€»è€—æ—¶: 567.89ms

[ä¸»æ¨¡å‹] æ­¥éª¤3: VRTå¤„ç†ä¸èåˆ
  [VRT] å¼€å§‹ç¼–ç é˜¶æ®µï¼ˆ4ä¸ªStageï¼Œæ¯ä¸ªStageåèåˆï¼‰
  [VRT] Stage 1 (1xåˆ†è¾¨ç‡)è€—æ—¶: 234.56ms
  [VRT] Stage 2 (1/2xåˆ†è¾¨ç‡)è€—æ—¶: 269.33ms
  ...

[ä¸»æ¨¡å‹] VRTå¤„ç†æ€»è€—æ—¶: 1234.56ms

================================================================================
å‰å‘ä¼ æ’­æ€»è€—æ—¶: 1930.85ms
  - Spikeç¼–ç å™¨: 128.40ms (6.7%)
  - Spikeæ—¶é—´è‡ªæ³¨æ„åŠ›: 567.89ms (29.4%)
  - VRTå¤„ç†ä¸èåˆ: 1234.56ms (63.9%)
================================================================================
```

### ä½¿ç”¨è°ƒè¯•åŠŸèƒ½

#### æ–¹æ³•1: è¿è¡Œæµ‹è¯•è„šæœ¬

```bash
cd /home/mallm/henry/Deblur
python test_timing_debug.py
```

#### æ–¹æ³•2: åœ¨è®­ç»ƒä¸­æŸ¥çœ‹

**é‡å®šå‘åˆ°æ–‡ä»¶**
```bash
python src/train.py > timing_debug.log 2>&1
```

**ä½¿ç”¨grepè¿‡æ»¤å…³é”®ä¿¡æ¯**
```bash
python src/train.py 2>&1 | grep "æ€»è€—æ—¶"
```

---

## ğŸ’¡ ä¼˜åŒ–å»ºè®®

### ç»ˆæä¼˜åŒ–ç»„åˆ

| é…ç½® | æ˜¾å­˜ | æ­¥éª¤æ—¶é—´ | ååé‡ | Epochæ—¶é—´ | æ€»è®­ç»ƒæ—¶é—´(50 epochs) |
|------|------|----------|--------|-----------|---------------------|
| **å½“å‰** | 32GB | 6.0s | 0.5 samp/s | 17.7h | 88.5h |
| + 8bit Adam | 23GB | 4.0s | 1.5 samp/s | 5.9h | 29.5h |
| + batch=2 | 26GB | 4.0s | 1.5 samp/s | 3.0h | 15.0h |
| + batch=3 | 29GB | 3.5s | 2.6 samp/s | 2.0h | 10.0h |
| + no checkpoint | 34GB | 2.5s | 3.6 samp/s | 1.4h | **7.0h** |

**æœ€ä¼˜é…ç½®ï¼šbatch=3 + 8bit Adam + no checkpoint**
- æ˜¾å­˜å ç”¨ï¼š34GB (70% of 48GB) âœ…
- è®­ç»ƒé€Ÿåº¦ï¼š3.6 samples/s âœ…
- æ€»æ—¶é—´ï¼š7å°æ—¶ (vs å½“å‰88.5å°æ—¶) âœ…
- **é€Ÿåº¦æå‡ï¼š12.6Ã—** ğŸš€

### ç«‹å³è¡ŒåŠ¨

```bash
# 1. å®‰è£…8-bit optimizer
pip install bitsandbytes

# 2. ä¿®æ”¹é…ç½®
# configs/deblur/vrt_spike_baseline.yaml
TRAIN:
  OPTIM:
    TYPE: adamw8bit
  BATCH_SIZE: 3

MODEL:
  VRT:
    use_checkpoint_attn: false
    use_checkpoint_ffn: false

# 3. é‡æ–°è®­ç»ƒ
python src/train.py --cfg configs/deblur/vrt_spike_baseline.yaml

# é¢„æœŸç»“æœï¼š
# - æ˜¾å­˜å ç”¨: 34GB (was 32GB)
# - è®­ç»ƒé€Ÿåº¦: 3.6 samples/s (was 0.5)
# - è®­ç»ƒæ—¶é—´: 7å°æ—¶ (was 88.5å°æ—¶)
```

### åˆ†æ­¥ä¼˜åŒ–æ–¹æ¡ˆ

#### ğŸ¥‡ ç¬¬ä¸€æ­¥ï¼š8-bit Adam optimizer â­â­â­â­â­

**åŸç†**ï¼š
- å‡å°‘optimizer states: 12GB â†’ 3GB
- æ€»æ˜¾å­˜: 32GB â†’ 23GB
- **å…è®¸batch_size = 2-3**

**é¢„æœŸæ•ˆæœ**ï¼š
```
batch=2: 4s/step â†’ 1.5 samples/s (3Ã— faster)
batch=3: 3.5s/step â†’ 2.5 samples/s (5Ã— faster)
```

#### ğŸ¥ˆ ç¬¬äºŒæ­¥ï¼šç¦ç”¨Gradient Checkpointing â­â­â­â­

**å‰æ**ï¼šå¿…é¡»å…ˆè§£å†³æ˜¾å­˜é—®é¢˜ï¼ˆä½¿ç”¨8-bit Adamï¼‰

**å®æ–½**ï¼š
```python
use_checkpoint_attn=False,
use_checkpoint_ffn=False,
```

**é¢„æœŸæ•ˆæœ**ï¼š
- åå‘ä¼ æ’­æ—¶é—´ï¼š4000ms â†’ 1800ms
- æ€»æ­¥éª¤æ—¶é—´ï¼š6s â†’ 4s (batch=1) æˆ– 4s â†’ 2.5s (batch=2)

#### ğŸ¥‰ ç¬¬ä¸‰æ­¥ï¼šä¼˜åŒ–VGG Loss â­â­

**æ–¹æ¡ˆ**ï¼š
1. ä½¿ç”¨æ›´è½»é‡çš„LPIPS tinyç‰ˆæœ¬
2. é™ä½VGG lossè®¡ç®—é¢‘ç‡ï¼ˆæ¯Næ­¥è®¡ç®—ä¸€æ¬¡ï¼‰
3. Freeze VGGå‚æ•°å¹¶ä½¿ç”¨æ›´å°çš„ç‰¹å¾å±‚

**é¢„æœŸèŠ‚çœ**ï¼š
- æ˜¾å­˜: 2GB â†’ 0.5GB
- è®¡ç®—æ—¶é—´: ~50ms â†’ ~20ms per step

---

## ğŸ“ æ€»ç»“

### æ ¸å¿ƒçœŸç›¸

1. **ç“¶é¢ˆç¡®å®åœ¨GPUè®¡ç®—**
   - åå‘ä¼ æ’­ï¼ˆ70-83%æ—¶é—´ï¼‰ï¼šGradient checkpointingä»£ä»·
   - å‰å‘ä¼ æ’­ï¼ˆ31%æ—¶é—´ï¼‰ï¼šVRTæ¨¡å‹å›ºæœ‰å¤æ‚åº¦
   - æ•°æ®åŠ è½½ï¼ˆ<0.01%æ—¶é—´ï¼‰ï¼šå®Œå…¨ä¸æ˜¯é—®é¢˜

2. **0.5 samples/sæ˜¯åˆç†çš„æ…¢é€Ÿ**
   - 6ç§’/æ­¥ = 1.8så‰å‘ + 4såå‘(checkpointing) + 0.2så…¶ä»–
   - batch_size=1å¯¼è‡´GPUåˆ©ç”¨ç‡ä½
   - è¿™ä¸æ˜¯"å¼‚å¸¸"ï¼Œè€Œæ˜¯å½“å‰é…ç½®çš„å¿…ç„¶ç»“æœ

3. **æ˜¾å­˜ç“¶é¢ˆé˜»æ­¢äº†æ€§èƒ½ä¼˜åŒ–**
   - Adam optimizerå ç”¨40%æ˜¾å­˜ï¼ˆ12GBï¼‰
   - æ— æ³•å¢å¤§batch size
   - å¿…é¡»ä½¿ç”¨gradient checkpointing

### å…³é”®è¡ŒåŠ¨

ğŸ¯ **ç¬¬ä¸€æ­¥ï¼š8-bit Adam optimizer**
- æœ€ç®€å•ã€æœ€æœ‰æ•ˆ
- æ˜¾å­˜ï¼š32GB â†’ 23GB
- é€Ÿåº¦ï¼š0.5 â†’ 1.5 samples/s (3Ã—)

ğŸ¯ **ç¬¬äºŒæ­¥ï¼šå¢å¤§batch sizeåˆ°3**
- éœ€è¦ç¬¬ä¸€æ­¥å®Œæˆ
- é€Ÿåº¦ï¼š1.5 â†’ 2.6 samples/s (1.7Ã—)

ğŸ¯ **ç¬¬ä¸‰æ­¥ï¼šç¦ç”¨gradient checkpointing**
- éœ€è¦å‰ä¸¤æ­¥å®Œæˆ
- é€Ÿåº¦ï¼š2.6 â†’ 3.6 samples/s (1.4Ã—)

**ç´¯è®¡æå‡ï¼š0.5 â†’ 3.6 samples/s = 7.2Ã— faster**

---

## ğŸ”§ æ•…éšœæ’é™¤

### ç»ˆç«¯æ˜¾ç¤ºä¹±ç 

ç¡®ä¿ç»ˆç«¯æ”¯æŒANSIè½¬ä¹‰åºåˆ—å’ŒUTF-8ç¼–ç ã€‚

### æ–‡ä»¶æœªç”Ÿæˆ

æ£€æŸ¥ï¼š
1. `ENABLE_TIMING_LOG` æ˜¯å¦ä¸º `true`
2. `TIMING_FILE` æ˜¯å¦ä¸º `true`
3. æ—¥å¿—ç›®å½•æ˜¯å¦æœ‰å†™æƒé™
4. æ˜¯å¦åœ¨ä¸»è¿›ç¨‹ä¸­è¿è¡Œ

### è€—æ—¶ä¸å‡†ç¡®

å¯¹äºGPUæ“ä½œï¼š
1. ä½¿ç”¨ CUDA äº‹ä»¶è€Œä¸æ˜¯ `time.time()`
2. ç¡®ä¿åœ¨è®°å½•å‰è°ƒç”¨ `torch.cuda.synchronize()`

### æ€§èƒ½å½±å“

å¦‚æœæ‹…å¿ƒæ€§èƒ½å½±å“ï¼š
1. å¢å¤§ `console_update_interval` å’Œ `file_flush_interval`
2. è®¾ç½® `TIMING_CONSOLE: false` åªè®°å½•åˆ°æ–‡ä»¶
3. è®¾ç½® `ENABLE_TIMING_LOG: false` å®Œå…¨å…³é—­

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025-10-21  
**æ•´åˆè‡ª**: TIMING_ANALYSIS_REVELATION.md, TIMING_LOG.md, TIMING_DEBUG_GUIDE.md


