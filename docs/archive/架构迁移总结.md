# VRT+Spike 架构迁移总结

## 迁移完成状态 ✓

**日期**: 2025-10-09  
**状态**: 已完成从旧版（Concat→1×1）到新版（Cross-Attention）的架构迁移  
**验证**: 代码通过 linter 检查，待运行模型验证

---

## 核心架构变更

### 旧版架构（已废弃）

```
输入模糊帧 (blur)           输入脉冲体素 (spike_vox)
      ↓                              ↓
  VRT 编码器                    SpikeEncoder3D
      ↓                              ↓
    Fr_i                           Fs_i
      ↓                              ↓
      └──────→ Concat ←──────────────┘
                 ↓
            1×1 Conv 降维
                 ↓
              Fused_i
                 ↓
            VRT TMSA
                 ↓
            VRT 解码器
                 ↓
           输出清晰帧 (recon)
```

**特点**：
- 融合位置：进入 TMSA **之前**
- 融合方式：通道维 Concat + 1×1 卷积
- Spike 分支：仅 3D 卷积编码，无时序建模

### 新版架构（当前实现）

```
输入模糊帧 (blur)                    输入脉冲体素 (spike_vox)
      ↓                                       ↓
  VRT 编码器                             SpikeEncoder3D
      ↓                                       ↓
  VRT TMSA                                  Fs_i
      ↓                                       ↓
    Fr_i                           时间维 Self-Attention
      ↓                                       ↓
      │                                     Fs'_i
      │                                       │
      └─────→ Cross-Attention ←──────────────┘
              (Q=Fr_i, K/V=Fs'_i)
                     ↓
                   Ff_i
                     ↓
               VRT 解码器
                     ↓
              输出清晰帧 (recon)
```

**特点**：
- 融合位置：完成各自时域建模**之后**
- 融合方式：时间维 Cross-Attention（Q 来自 RGB，K/V 来自 Spike）
- Spike 分支：3D 编码 + 时间维 Self-Attention
- RGB 分支：完整保留 VRT 的 TMSA 能力

---

## 代码变更清单

### 已删除文件
- ❌ `src/models/fusion/concat_1x1_pre_tmsa.py`

### 新增文件
- ✅ `src/models/spike_temporal_sa.py` - Spike 时间维 Self-Attention
  - `TemporalSelfAttentionBlock`: 单尺度 Block
  - `SpikeTemporalSA`: 多尺度封装
  
- ✅ `src/models/fusion/cross_attn_temporal.py` - 时间维 Cross-Attention 融合
  - `TemporalCrossAttnFuse`: 单尺度融合
  - `MultiScaleTemporalCrossAttnFuse`: 多尺度封装

- ✅ `scripts/validate_model_shapes.py` - 模型验证工具

### 重构文件
- 🔄 `src/models/integrate_vrt.py` - 完全重写以支持新架构
- 🔄 `src/train.py` - 添加 `tsa_heads` 和 `fuse_heads` 参数支持
- 🔄 `configs/deblur/vrt_spike_baseline.yaml` - 添加新架构配置项

### 更新文档
- 📝 `docs/VRT+Spike Baseline 实施进度.md` - 详细记录迁移过程

---

## 配置变更

### `configs/deblur/vrt_spike_baseline.yaml`

**新增字段**:
```yaml
MODEL:
  LAYERS: 7                          # 新增：尺度数
  SPIKE_TSA:                         # 新增：Spike 时间维 Self-Attention 配置
    HEADS: 4
  FUSE:
    TYPE: TemporalCrossAttn          # 修改：从 Concat1x1PreTMSA 改为 TemporalCrossAttn
    HEADS: 4                         # 新增：融合模块注意力头数
```

---

## 关键参数约束

| 参数 | 值 | 说明 | 是否可调 |
|------|-----|------|---------|
| `SPIKE_TSA.HEADS` | 4 | Spike Temporal SA 注意力头数 | ❌ 固定 |
| `FUSE.HEADS` | 4 | Cross-Attention 注意力头数 | ❌ 固定 |
| Temporal SA Block 数 | 1/尺度 | 每尺度的 Block 数量 | ❌ 固定 |
| Dropout | 0.0 | 所有注意力层的 dropout | ❌ 固定 |
| `CHANNELS_PER_SCALE` | [120]*7 | 各尺度通道数（需与 VRT 对齐） | ⚠️ 需匹配 VRT |

---

## 验证步骤

### 1. 模型构建验证
```bash
cd c:/Users/WHY/Projects/Academic/Research/Deblur
python scripts/validate_model_shapes.py
```

**预期输出**:
- ✓ 前向传播成功
- ✓ 各尺度形状一致性检查通过
- ✓ 通道数匹配 `channels_per_scale`

### 2. 训练验证（待 VRT 子模块引入后）
```bash
# Linux
bash scripts/launch_train.sh

# Windows
pwsh scripts/launch_train.ps1
```

---

## 与开发指导文档的对齐

### 严格遵守的约束
- ✅ 融合位置：TMSA **之后**（第 4.5 节）
- ✅ 融合方式：时间维 Cross-Attention（第 5.4 节）
- ✅ Spike 分支：3D 编码 + Temporal Self-Attention（第 5.2 节）
- ✅ 注意力头数：固定为 4（第 5.2、5.4 节）
- ✅ Dropout：固定为 0（第 5.2、5.4 节）
- ✅ Block 数：每尺度固定为 1（第 5.2 节）
- ✅ 不引入额外损失/正则（第 6.1 节）
- ✅ 不改动 VRT 内部实现（第 5.5 节）

### 关键代码片段对齐
- ✅ `TemporalSelfAttentionBlock` 严格按第 10.1 节实现
- ✅ `TemporalCrossAttnFuse` 严格按第 10.2 节实现
- ✅ 集成流程严格按第 10.3 节示意

---

## 架构对比表

| 对比维度 | 旧版 | 新版 |
|---------|------|------|
| 融合时机 | TMSA **之前** | TMSA **之后** |
| 融合维度 | 通道维（Concat） | 时间维（Attention） |
| Spike 时序建模 | ❌ 无 | ✅ 有（Temporal Self-Attention） |
| RGB 时序建模 | 融合后才做 | 融合前已完成（VRT TMSA） |
| 信息流向 | 对称融合 | RGB 为主（Query），Spike 辅助（Key/Value） |
| 参数量 | 较少（仅 1×1 Conv） | 较多（两组 Attention） |
| 融合模块 | `Concat1x1PreTMSA` | `TemporalCrossAttnFuse` + `SpikeTemporalSA` |

---

## 下一步工作

### 立即执行
1. ✅ **已完成**: 代码迁移与文档更新
2. ⏳ **待执行**: 运行 `scripts/validate_model_shapes.py` 验证模型

### 训练前准备
3. 确保 VRT 子模块正确引入（`third_party/VRT`）
4. 准备数据集并运行 `scripts/prepare_data.py`
5. 验证数据加载与体素化流程

### 训练与验证
6. 启动训练并监控指标（PSNR/LPIPS/SSIM）
7. 对照"无 Spike"VRT 验证性能（要求: `PSNR ≥ base − 0.05dB`）
8. 保存可视化对比（blur/recon/sharp 三列）

---

## 常见问题排查

### Q1: 前向传播失败
- 检查 VRT 子模块是否正确引入
- 检查各尺度通道数是否与 VRT 对齐
- 运行 `scripts/validate_model_shapes.py` 获取详细错误

### Q2: 形状不匹配
- 确认 `CHANNELS_PER_SCALE` 与 VRT 配置一致
- 检查 `SpikeEncoder3D` 的时间维下采样是否对齐 VRT

### Q3: 显存溢出
- 减小 `BATCH_SIZE`（默认 4）
- 减小 `CROP_SIZE`（默认 256）
- 确认 `heads=4` 和 `dropout=0` 未被修改

---

## 参考文档

- 📖 **开发指导**: `docs/Vrt+spike 视频去模糊 Baseline 开发指导.md`
- 📊 **实施进度**: `docs/VRT+Spike Baseline 实施进度.md`
- ⚙️ **配置文件**: `configs/deblur/vrt_spike_baseline.yaml`

---

**迁移完成日期**: 2025-10-09  
**验证状态**: 代码 linter 检查通过 ✓，待运行时验证



