#!/usr/bin/env python3
"""
ç¡¬ä»¶èµ„æºå¯¹è®­ç»ƒé€Ÿåº¦çš„å½±å“åˆ†æå·¥å…·

è¿™ä¸ªå·¥å…·ä¼šï¼š
1. æ£€æµ‹ç³»ç»Ÿç¡¬ä»¶èµ„æºï¼ˆGPUã€CPUã€å†…å­˜ï¼‰
2. åˆ†æGPUæ˜¾å­˜ä½¿ç”¨æƒ…å†µï¼ˆåŒ…æ‹¬CUDAç¼“å­˜ï¼‰
3. è¿è¡Œè½»é‡çº§åŸºå‡†æµ‹è¯•
4. åˆ†æè®­ç»ƒé…ç½®çš„å¯è¡Œæ€§
5. è§£æè®­ç»ƒæ—¥å¿—å¹¶åˆ†ææ€§èƒ½ç“¶é¢ˆï¼ˆå¯é€‰ï¼‰
6. æä¾›ä¼˜åŒ–å»ºè®®å’Œæ¨èé…ç½®

ä½¿ç”¨åœºæ™¯ï¼š
- å…‹éš†é¡¹ç›®åé¦–æ¬¡è¿è¡Œ
- æ›´æ¢ç¡¬ä»¶ç¯å¢ƒ
- è®­ç»ƒé…ç½®ä¼˜åŒ–
- è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ€§èƒ½åˆ†æ
"""

import os
import sys
import yaml
import time
import torch
import psutil
import subprocess
import re
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from collections import defaultdict

# æ·»åŠ è·¯å¾„ - æ”¯æŒä»ä»»æ„ä½ç½®è¿è¡Œ
SCRIPT_DIR = Path(__file__).parent.resolve()
REPO_ROOT = SCRIPT_DIR.parent
sys.path.insert(0, str(REPO_ROOT))
sys.path.insert(0, str(REPO_ROOT / "third_party" / "VRT"))


class HardwareAnalyzer:
    """ç¡¬ä»¶èµ„æºåˆ†æå™¨"""
    
    def __init__(self):
        self.gpu_info = []
        self.cpu_count = 0
        self.ram_gb = 0
        self.benchmark_results = {}
        
    def detect_hardware(self):
        """æ£€æµ‹ç¡¬ä»¶é…ç½®"""
        print("=" * 80)
        print("ç¡¬ä»¶èµ„æºæ£€æµ‹".center(80))
        print("=" * 80)
        
        # GPUæ£€æµ‹
        if torch.cuda.is_available():
            num_gpus = torch.cuda.device_count()
            print(f"\nâœ… æ£€æµ‹åˆ° {num_gpus} ä¸ªGPU:")
            
            for i in range(num_gpus):
                props = torch.cuda.get_device_properties(i)
                gpu_name = props.name
                gpu_memory_gb = props.total_memory / (1024 ** 3)
                compute_capability = f"{props.major}.{props.minor}"
                
                self.gpu_info.append({
                    'index': i,
                    'name': gpu_name,
                    'memory_gb': gpu_memory_gb,
                    'compute_capability': compute_capability,
                    'multi_processor_count': props.multi_processor_count
                })
                
                print(f"  GPU {i}: {gpu_name}")
                print(f"    æ˜¾å­˜: {gpu_memory_gb:.1f} GB")
                print(f"    è®¡ç®—èƒ½åŠ›: {compute_capability}")
                print(f"    SMæ•°é‡: {props.multi_processor_count}")
        else:
            print("\nâŒ æœªæ£€æµ‹åˆ°å¯ç”¨çš„GPU")
            print("   æœ¬é¡¹ç›®éœ€è¦GPUè¿›è¡Œè®­ç»ƒ")
            return False
        
        # CPUæ£€æµ‹
        self.cpu_count = psutil.cpu_count(logical=True)
        cpu_freq = psutil.cpu_freq()
        print(f"\nğŸ’» CPUä¿¡æ¯:")
        print(f"  é€»è¾‘æ ¸å¿ƒæ•°: {self.cpu_count}")
        if cpu_freq:
            print(f"  å½“å‰é¢‘ç‡: {cpu_freq.current:.0f} MHz")
            print(f"  æœ€å¤§é¢‘ç‡: {cpu_freq.max:.0f} MHz")
        
        # å†…å­˜æ£€æµ‹
        mem = psutil.virtual_memory()
        self.ram_gb = mem.total / (1024 ** 3)
        print(f"\nğŸ§  ç³»ç»Ÿå†…å­˜:")
        print(f"  æ€»å†…å­˜: {self.ram_gb:.1f} GB")
        print(f"  å¯ç”¨å†…å­˜: {mem.available / (1024 ** 3):.1f} GB")
        print(f"  ä½¿ç”¨ç‡: {mem.percent:.1f}%")
        
        # ç£ç›˜ä¿¡æ¯
        disk = psutil.disk_usage('/')
        print(f"\nğŸ’¾ ç£ç›˜ç©ºé—´:")
        print(f"  æ€»ç©ºé—´: {disk.total / (1024 ** 3):.1f} GB")
        print(f"  å¯ç”¨ç©ºé—´: {disk.free / (1024 ** 3):.1f} GB")
        print(f"  ä½¿ç”¨ç‡: {disk.percent:.1f}%")
        
        return True
    
    def analyze_gpu_memory_details(self):
        """è¯¦ç»†åˆ†æGPUæ˜¾å­˜ä½¿ç”¨æƒ…å†µï¼ˆåŒ…æ‹¬CUDAç¼“å­˜ï¼‰"""
        print("\n" + "=" * 80)
        print("GPUæ˜¾å­˜è¯¦ç»†åˆ†æ".center(80))
        print("=" * 80)
        
        if not torch.cuda.is_available():
            print("\nâŒ CUDAä¸å¯ç”¨ï¼Œè·³è¿‡æ˜¾å­˜åˆ†æ")
            return
        
        # nvidia-smiè§†è§’çš„æ˜¾å­˜ä½¿ç”¨
        print("\nğŸ“Š nvidia-smi æ˜¾å­˜ä½¿ç”¨æƒ…å†µ:")
        try:
            result = subprocess.run(
                ["nvidia-smi", "--query-gpu=index,memory.used,memory.total", 
                 "--format=csv,noheader,nounits"],
                capture_output=True,
                text=True,
                check=True
            )
            
            for line in result.stdout.strip().split('\n'):
                if line:
                    idx, used, total = line.split(', ')
                    used_gb = int(used) / 1024
                    total_gb = int(total) / 1024
                    pct = (int(used) / int(total)) * 100
                    print(f"  GPU {idx}: {used_gb:.2f} GB / {total_gb:.2f} GB ({pct:.1f}%)")
        except Exception as e:
            print(f"  âš ï¸  æ— æ³•è·å–nvidia-smiä¿¡æ¯: {e}")
        
        # PyTorchè§†è§’çš„æ˜¾å­˜ä½¿ç”¨
        print("\nğŸ“Š PyTorch æ˜¾å­˜è·Ÿè¸ª:")
        for i in range(len(self.gpu_info)):
            print(f"\n  GPU {i}:")
            torch.cuda.reset_peak_memory_stats(i)
            
            allocated = torch.cuda.memory_allocated(i) / 1024**3
            reserved = torch.cuda.memory_reserved(i) / 1024**3
            max_allocated = torch.cuda.max_memory_allocated(i) / 1024**3
            max_reserved = torch.cuda.max_memory_reserved(i) / 1024**3
            
            print(f"    å·²åˆ†é… (æ´»è·ƒtensor): {allocated:.2f} GB")
            print(f"    å·²ä¿ç•™ (PyTorchç¼“å­˜): {reserved:.2f} GB")
            print(f"    å³°å€¼å·²åˆ†é…: {max_allocated:.2f} GB")
            print(f"    å³°å€¼å·²ä¿ç•™: {max_reserved:.2f} GB")
            
            if reserved > allocated + 0.5:
                cache_gb = reserved - allocated
                print(f"    ğŸ’¡ CUDAç¼“å­˜: {cache_gb:.2f} GB")
                print(f"       (è¿™æ˜¯PyTorchä¸ºæ€§èƒ½ä¼˜åŒ–ä¿ç•™çš„å†…å­˜æ± )")
        
        # æŸ¥æ‰¾GPUè¿›ç¨‹
        print("\nğŸ“Š å½“å‰GPUè¿›ç¨‹:")
        try:
            result = subprocess.run(
                ["nvidia-smi", "--query-compute-apps=pid,process_name,used_memory",
                 "--format=csv,noheader"],
                capture_output=True,
                text=True,
                check=True
            )
            
            if result.stdout.strip():
                for line in result.stdout.strip().split('\n'):
                    if line:
                        parts = line.split(', ')
                        if len(parts) == 3:
                            pid, name, mem = parts
                            mem_gb = int(mem.replace(' MiB', '')) / 1024
                            print(f"  PID {pid}: {name} - {mem_gb:.2f} GB")
            else:
                print("  (æ— æ´»è·ƒè¿›ç¨‹)")
        except Exception as e:
            print(f"  âš ï¸  æ— æ³•è·å–è¿›ç¨‹ä¿¡æ¯: {e}")
        
        # æ˜¾å­˜ä½¿ç”¨å»ºè®®
        print("\nğŸ’¡ æ˜¾å­˜ä¼˜åŒ–æç¤º:")
        print("  â€¢ PyTorchä½¿ç”¨CUDAç¼“å­˜åˆ†é…å™¨æ¥æå‡æ€§èƒ½")
        print("  â€¢ 'nvidia-smi'æ˜¾ç¤ºçš„æ˜¯æ€»ä¿ç•™å†…å­˜(reserved)")
        print("  â€¢ 'torch.cuda.memory_allocated()'æ˜¾ç¤ºçš„æ˜¯å®é™…ä½¿ç”¨å†…å­˜")
        print("  â€¢ å·®å€¼æ˜¯PyTorchçš„å†…å­˜ç¼“å­˜æ± ï¼Œç”¨äºå¿«é€Ÿåˆ†é…tensor")
        print("  â€¢ å¦‚æœé‡åˆ°OOMï¼Œå¯ä»¥å°è¯•:")
        print("    1. å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ(AMP) - å‡å°‘40-50%æ˜¾å­˜")
        print("    2. ä½¿ç”¨gradient checkpointing")
        print("    3. å‡å°batch size")
        print("    4. ä½¿ç”¨torch.cuda.empty_cache()æ¸…ç†ç¼“å­˜(ä¸´æ—¶æ–¹æ¡ˆ)")
    
    def run_gpu_benchmark(self):
        """è¿è¡ŒGPUåŸºå‡†æµ‹è¯•"""
        print("\n" + "=" * 80)
        print("GPUæ€§èƒ½åŸºå‡†æµ‹è¯•".center(80))
        print("=" * 80)
        print("\nâ±ï¸  æ­£åœ¨è¿è¡Œè½»é‡çº§åŸºå‡†æµ‹è¯•ï¼ˆçº¦30ç§’ï¼‰...")
        
        if not self.gpu_info:
            print("âŒ æ— GPUå¯ç”¨ï¼Œè·³è¿‡åŸºå‡†æµ‹è¯•")
            return
        
        # å¯¹æ¯ä¸ªGPUè¿›è¡Œæµ‹è¯•
        for gpu in self.gpu_info:
            gpu_id = gpu['index']
            print(f"\næµ‹è¯• GPU {gpu_id}: {gpu['name']}")
            
            torch.cuda.set_device(gpu_id)
            torch.cuda.empty_cache()
            
            # æµ‹è¯•1: çŸ©é˜µä¹˜æ³•æ€§èƒ½ (FP32)
            print("  [1/4] FP32çŸ©é˜µä¹˜æ³•...")
            size = 4096
            a = torch.randn(size, size, device=f'cuda:{gpu_id}')
            b = torch.randn(size, size, device=f'cuda:{gpu_id}')
            
            torch.cuda.synchronize()
            start = time.time()
            for _ in range(10):
                c = torch.matmul(a, b)
            torch.cuda.synchronize()
            fp32_time = (time.time() - start) / 10
            fp32_tflops = (2 * size ** 3) / (fp32_time * 1e12)
            
            # æµ‹è¯•2: FP16æ€§èƒ½
            print("  [2/4] FP16çŸ©é˜µä¹˜æ³•...")
            a_fp16 = a.half()
            b_fp16 = b.half()
            
            torch.cuda.synchronize()
            start = time.time()
            for _ in range(10):
                c_fp16 = torch.matmul(a_fp16, b_fp16)
            torch.cuda.synchronize()
            fp16_time = (time.time() - start) / 10
            fp16_tflops = (2 * size ** 3) / (fp16_time * 1e12)
            
            # æµ‹è¯•3: æ˜¾å­˜å¸¦å®½
            print("  [3/4] æ˜¾å­˜å¸¦å®½æµ‹è¯•...")
            size_mb = 1024  # 1GB
            data = torch.randn(size_mb * 1024 * 1024 // 4, device=f'cuda:{gpu_id}')
            
            torch.cuda.synchronize()
            start = time.time()
            for _ in range(10):
                data = data * 2.0
            torch.cuda.synchronize()
            bandwidth_time = (time.time() - start) / 10
            bandwidth_gb_s = (size_mb / 1024) / bandwidth_time
            
            # æµ‹è¯•4: å°æ‰¹é‡æ¨ç†å»¶è¿Ÿ
            print("  [4/4] æ¨ç†å»¶è¿Ÿæµ‹è¯•...")
            model = torch.nn.Sequential(
                torch.nn.Conv2d(3, 64, 3, padding=1),
                torch.nn.ReLU(),
                torch.nn.Conv2d(64, 64, 3, padding=1),
                torch.nn.ReLU()
            ).to(f'cuda:{gpu_id}')
            
            test_input = torch.randn(1, 3, 256, 256, device=f'cuda:{gpu_id}')
            
            # Warmup
            for _ in range(5):
                _ = model(test_input)
            
            torch.cuda.synchronize()
            start = time.time()
            for _ in range(50):
                _ = model(test_input)
            torch.cuda.synchronize()
            inference_time = (time.time() - start) / 50 * 1000  # ms
            
            # ä¿å­˜ç»“æœ
            self.benchmark_results[gpu_id] = {
                'fp32_tflops': fp32_tflops,
                'fp16_tflops': fp16_tflops,
                'bandwidth_gb_s': bandwidth_gb_s,
                'inference_latency_ms': inference_time,
                'fp16_speedup': fp16_tflops / fp32_tflops if fp32_tflops > 0 else 0
            }
            
            # æ¸…ç†
            del a, b, c, a_fp16, b_fp16, c_fp16, data, model, test_input
            torch.cuda.empty_cache()
        
        # æ‰“å°ç»“æœ
        print("\n" + "-" * 80)
        print("åŸºå‡†æµ‹è¯•ç»“æœ:")
        print("-" * 80)
        
        for gpu_id, results in self.benchmark_results.items():
            print(f"\nGPU {gpu_id}:")
            print(f"  FP32æ€§èƒ½: {results['fp32_tflops']:.2f} TFLOPS")
            print(f"  FP16æ€§èƒ½: {results['fp16_tflops']:.2f} TFLOPS")
            print(f"  FP16åŠ é€Ÿæ¯”: {results['fp16_speedup']:.2f}x")
            print(f"  æ˜¾å­˜å¸¦å®½: {results['bandwidth_gb_s']:.1f} GB/s")
            print(f"  æ¨ç†å»¶è¿Ÿ: {results['inference_latency_ms']:.2f} ms")
    
    def estimate_training_requirements(self, config_path: str) -> Dict:
        """ä¼°ç®—è®­ç»ƒèµ„æºéœ€æ±‚"""
        print("\n" + "=" * 80)
        print("è®­ç»ƒèµ„æºéœ€æ±‚åˆ†æ".center(80))
        print("=" * 80)
        
        # åŠ è½½é…ç½®
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)
        
        batch_size = config['TRAIN']['BATCH_SIZE']
        gradient_accum = config['TRAIN']['GRADIENT_ACCUMULATION_STEPS']
        crop_size = config['DATA']['CROP_SIZE']
        clip_len = config['DATA']['CLIP_LEN']
        
        # æ•°æ®åŠ è½½é…ç½®
        total_workers = config['DATALOADER']['TOTAL_WORKERS']
        cache_size_gb = config['DATA']['CACHE_SIZE_GB']
        
        print(f"\nğŸ“‹ å½“å‰é…ç½®:")
        print(f"  Batch Size (per GPU): {batch_size}")
        print(f"  Gradient Accumulation: {gradient_accum}")
        print(f"  Effective Batch Size: {batch_size * gradient_accum * len(self.gpu_info)}")
        print(f"  Crop Size: {crop_size}x{crop_size}")
        print(f"  Clip Length: {clip_len}")
        print(f"  DataLoader Workers: {total_workers}")
        print(f"  Cache Size: {cache_size_gb} GB per worker")
        
        # ä¼°ç®—GPUæ˜¾å­˜éœ€æ±‚
        print(f"\nğŸ® GPUæ˜¾å­˜éœ€æ±‚ä¼°ç®—:")
        
        # åŸºç¡€æ˜¾å­˜å ç”¨ï¼ˆç²—ç•¥ä¼°ç®—ï¼‰
        model_params_gb = 5.0  # VRT base + Spike fusionæ¨¡å‹çº¦5GB
        optimizer_states_gb = model_params_gb * 2  # AdamWéœ€è¦2å€å‚æ•°é‡
        
        # å‰å‘ä¼ æ’­æ¿€æ´»å€¼ï¼ˆä¸batch sizeå’Œåˆ†è¾¨ç‡ç›¸å…³ï¼‰
        # ä¼°ç®—å…¬å¼: batch * clip * channels * H * W * 4 (FP32) * layers
        activation_gb = batch_size * clip_len * 128 * crop_size * crop_size * 4 / (1024**3) * 8
        
        # æ¢¯åº¦ï¼ˆçº¦ç­‰äºæ¨¡å‹å‚æ•°ï¼‰
        gradient_gb = model_params_gb
        
        # PyTorch CUDAç¼“å­˜ï¼ˆç»éªŒå€¼ï¼‰
        cuda_cache_gb = 3.0
        
        total_gpu_memory_fp32 = (model_params_gb + optimizer_states_gb + 
                                  activation_gb + gradient_gb + cuda_cache_gb)
        
        # FP16æ··åˆç²¾åº¦å¯ä»¥å‡å°‘çº¦40-50%æ˜¾å­˜
        total_gpu_memory_fp16 = total_gpu_memory_fp32 * 0.55
        
        print(f"  æ¨¡å‹å‚æ•°: ~{model_params_gb:.1f} GB")
        print(f"  ä¼˜åŒ–å™¨çŠ¶æ€: ~{optimizer_states_gb:.1f} GB")
        print(f"  æ¿€æ´»å€¼ (batch={batch_size}): ~{activation_gb:.1f} GB")
        print(f"  æ¢¯åº¦: ~{gradient_gb:.1f} GB")
        print(f"  CUDAç¼“å­˜: ~{cuda_cache_gb:.1f} GB")
        print(f"  ---")
        print(f"  é¢„è®¡æ€»éœ€æ±‚ (FP32): ~{total_gpu_memory_fp32:.1f} GB")
        print(f"  é¢„è®¡æ€»éœ€æ±‚ (FP16): ~{total_gpu_memory_fp16:.1f} GB")
        
        # ä¼°ç®—CPUå’Œå†…å­˜éœ€æ±‚
        print(f"\nğŸ’» CPU/å†…å­˜éœ€æ±‚ä¼°ç®—:")
        
        # è§£æworkersé…ç½®
        if isinstance(total_workers, str):
            if total_workers == "auto" or total_workers.startswith("cpu*"):
                if total_workers.startswith("cpu*"):
                    ratio = float(total_workers.replace("cpu*", ""))
                    workers_per_gpu = int(self.cpu_count * ratio / len(self.gpu_info))
                else:
                    workers_per_gpu = int(self.cpu_count * 0.8 / len(self.gpu_info))
            else:
                workers_per_gpu = int(total_workers) // len(self.gpu_info)
        else:
            workers_per_gpu = total_workers // len(self.gpu_info)
        
        total_workers_count = workers_per_gpu * len(self.gpu_info)
        
        # å†…å­˜éœ€æ±‚ = cache * workers + dataset overhead
        ram_for_cache = cache_size_gb * total_workers_count
        ram_overhead = 5.0  # ç³»ç»Ÿå’Œå…¶ä»–å¼€é”€
        total_ram_needed = ram_for_cache + ram_overhead
        
        print(f"  æ¨èWorkersæ•°: {workers_per_gpu} per GPU (æ€»è®¡ {total_workers_count})")
        print(f"  Cacheå ç”¨: {cache_size_gb} GB/worker Ã— {total_workers_count} = {ram_for_cache:.1f} GB")
        print(f"  ç³»ç»Ÿå¼€é”€: ~{ram_overhead:.1f} GB")
        print(f"  é¢„è®¡æ€»éœ€æ±‚: ~{total_ram_needed:.1f} GB")
        
        return {
            'batch_size': batch_size,
            'gradient_accum': gradient_accum,
            'gpu_memory_fp32': total_gpu_memory_fp32,
            'gpu_memory_fp16': total_gpu_memory_fp16,
            'ram_needed': total_ram_needed,
            'workers_per_gpu': workers_per_gpu,
            'total_workers': total_workers_count
        }
    
    def generate_recommendations(self, requirements: Dict):
        """ç”Ÿæˆé…ç½®ä¼˜åŒ–å»ºè®®"""
        print("\n" + "=" * 80)
        print("é…ç½®ä¼˜åŒ–å»ºè®®".center(80))
        print("=" * 80)
        
        recommendations = []
        warnings = []
        optimal_config = {}
        
        # æ£€æŸ¥GPUæ˜¾å­˜
        min_gpu_memory = min([g['memory_gb'] for g in self.gpu_info])
        
        print(f"\nğŸ® GPUé…ç½®å»ºè®®:")
        
        if min_gpu_memory < requirements['gpu_memory_fp32']:
            if min_gpu_memory >= requirements['gpu_memory_fp16']:
                recommendations.append({
                    'priority': 'HIGH',
                    'category': 'GPU',
                    'title': 'å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (AMP)',
                    'reason': f"å½“å‰GPUæ˜¾å­˜ ({min_gpu_memory:.1f} GB) ä¸è¶³ä»¥æ”¯æŒFP32è®­ç»ƒ ({requirements['gpu_memory_fp32']:.1f} GB)",
                    'action': 'åœ¨é…ç½®ä¸­æ·»åŠ : TRAIN.USE_AMP: true',
                    'expected_benefit': 'æ˜¾å­˜å‡å°‘çº¦45%, è®­ç»ƒé€Ÿåº¦æå‡20-30%',
                    'config_change': {'TRAIN': {'USE_AMP': True}}
                })
            else:
                warnings.append(f"âš ï¸  GPUæ˜¾å­˜å¯èƒ½ä¸è¶³: {min_gpu_memory:.1f} GB < {requirements['gpu_memory_fp16']:.1f} GB (FP16)")
                recommendations.append({
                    'priority': 'CRITICAL',
                    'category': 'GPU',
                    'title': 'å‡å°Batch Size',
                    'reason': f"GPUæ˜¾å­˜ä¸¥é‡ä¸è¶³",
                    'action': f'å°†BATCH_SIZEä»{requirements["batch_size"]}å‡å°åˆ°1ï¼Œæˆ–å¢åŠ GRADIENT_ACCUMULATION_STEPS',
                    'expected_benefit': 'ç¡®ä¿è®­ç»ƒå¯ä»¥è¿è¡Œ',
                    'config_change': {'TRAIN': {'BATCH_SIZE': 1, 'GRADIENT_ACCUMULATION_STEPS': requirements['gradient_accum'] * requirements['batch_size']}}
                })
        else:
            # GPUæ˜¾å­˜å……è¶³ï¼Œå¯ä»¥è€ƒè™‘å¢å¤§batch size
            available_memory = min_gpu_memory - requirements['gpu_memory_fp32']
            if available_memory > 5:
                potential_batch_increase = int(available_memory / (requirements['gpu_memory_fp32'] / requirements['batch_size'] * 0.4))
                if potential_batch_increase > 1:
                    recommendations.append({
                        'priority': 'MEDIUM',
                        'category': 'GPU',
                        'title': 'å¯ä»¥å¢å¤§Batch Size',
                        'reason': f"GPUæ˜¾å­˜å……è¶³ ({min_gpu_memory:.1f} GB)ï¼Œæœ‰ {available_memory:.1f} GBç©ºé—²",
                        'action': f'å¯ä»¥å°è¯•å°†BATCH_SIZEå¢åŠ åˆ° {requirements["batch_size"] + potential_batch_increase}',
                        'expected_benefit': 'è®­ç»ƒæ›´ç¨³å®šï¼Œå¯èƒ½æ”¶æ•›æ›´å¿«',
                        'config_change': {'TRAIN': {'BATCH_SIZE': requirements["batch_size"] + potential_batch_increase}}
                    })
        
        # æ£€æŸ¥FP16æ€§èƒ½
        if self.benchmark_results:
            avg_speedup = sum([r['fp16_speedup'] for r in self.benchmark_results.values()]) / len(self.benchmark_results)
            if avg_speedup > 1.5:
                recommendations.append({
                    'priority': 'HIGH',
                    'category': 'GPU',
                    'title': 'å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒä»¥æå‡é€Ÿåº¦',
                    'reason': f"GPUçš„FP16æ€§èƒ½æ˜¯FP32çš„{avg_speedup:.1f}å€",
                    'action': 'åœ¨é…ç½®ä¸­æ·»åŠ : TRAIN.USE_AMP: true',
                    'expected_benefit': f'è®­ç»ƒé€Ÿåº¦æå‡çº¦{(avg_speedup - 1) * 100:.0f}%',
                    'config_change': {'TRAIN': {'USE_AMP': True}}
                })
        
        # æ£€æŸ¥CPUå’Œå†…å­˜
        print(f"\nğŸ’» CPU/å†…å­˜é…ç½®å»ºè®®:")
        
        if self.ram_gb < requirements['ram_needed']:
            warnings.append(f"âš ï¸  ç³»ç»Ÿå†…å­˜å¯èƒ½ä¸è¶³: {self.ram_gb:.1f} GB < {requirements['ram_needed']:.1f} GB")
            
            # è®¡ç®—åˆé€‚çš„workeræ•°å’Œcache size
            safe_cache_size = (self.ram_gb * 0.7) / requirements['total_workers']
            safe_workers_ratio = (self.ram_gb * 0.7) / (requirements['total_workers'] * requirements['ram_needed'] / self.ram_gb)
            
            recommendations.append({
                'priority': 'HIGH',
                'category': 'CPU/RAM',
                'title': 'å‡å°‘DataLoaderå†…å­˜å ç”¨',
                'reason': f"ç³»ç»Ÿå†…å­˜ä¸è¶³ ({self.ram_gb:.1f} GB < {requirements['ram_needed']:.1f} GB)",
                'action': f'å‡å°‘CACHE_SIZE_GBåˆ°{safe_cache_size:.1f}æˆ–å‡å°‘workers',
                'expected_benefit': 'é¿å…OOMï¼Œç¡®ä¿ç¨³å®šè¿è¡Œ',
                'config_change': {
                    'DATA': {'CACHE_SIZE_GB': max(0.5, safe_cache_size)},
                    'DATALOADER': {'TOTAL_WORKERS': f"cpu*{max(0.3, safe_workers_ratio * 0.6):.1f}"}
                }
            })
        else:
            available_ram = self.ram_gb - requirements['ram_needed']
            if available_ram > 20:
                recommendations.append({
                    'priority': 'LOW',
                    'category': 'CPU/RAM',
                    'title': 'å¯ä»¥å¢åŠ Cache Size',
                    'reason': f"ç³»ç»Ÿå†…å­˜å……è¶³ ({self.ram_gb:.1f} GB)ï¼Œæœ‰ {available_ram:.1f} GBç©ºé—²",
                    'action': f'å¯ä»¥å¢åŠ CACHE_SIZE_GBåˆ° {requirements["ram_needed"] / requirements["total_workers"] + 1:.1f}',
                    'expected_benefit': 'æå‡æ•°æ®åŠ è½½é€Ÿåº¦',
                    'config_change': {'DATA': {'CACHE_SIZE_GB': min(3.0, requirements["ram_needed"] / requirements["total_workers"] + 1)}}
                })
        
        # CPU coresæ£€æŸ¥
        optimal_workers = int(self.cpu_count * 0.7 / len(self.gpu_info))
        if requirements['workers_per_gpu'] > self.cpu_count:
            recommendations.append({
                'priority': 'MEDIUM',
                'category': 'CPU/RAM',
                'title': 'è°ƒæ•´DataLoader Workersæ•°é‡',
                'reason': f"Workersæ•°({requirements['total_workers']})è¶…è¿‡CPUæ ¸å¿ƒæ•°({self.cpu_count})",
                'action': f'è®¾ç½®TOTAL_WORKERSä¸º"cpu*0.7" (çº¦{optimal_workers * len(self.gpu_info)}ä¸ªworkers)',
                'expected_benefit': 'é¿å…CPUè¿‡è½½',
                'config_change': {'DATALOADER': {'TOTAL_WORKERS': 'cpu*0.7'}}
            })
        
        # æ‰“å°å»ºè®®
        if warnings:
            print("\nâš ï¸  è­¦å‘Š:")
            for warning in warnings:
                print(f"  {warning}")
        
        print("\nğŸ“Š ä¼˜åŒ–å»ºè®® (æŒ‰ä¼˜å…ˆçº§æ’åº):\n")
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        priority_order = {'CRITICAL': 0, 'HIGH': 1, 'MEDIUM': 2, 'LOW': 3}
        recommendations.sort(key=lambda x: priority_order.get(x['priority'], 99))
        
        for i, rec in enumerate(recommendations, 1):
            priority_icon = {
                'CRITICAL': 'ğŸ”´',
                'HIGH': 'ğŸŸ ',
                'MEDIUM': 'ğŸŸ¡',
                'LOW': 'ğŸŸ¢'
            }.get(rec['priority'], 'âšª')
            
            print(f"{priority_icon} [{rec['priority']}] {rec['title']}")
            print(f"   åˆ†ç±»: {rec['category']}")
            print(f"   åŸå› : {rec['reason']}")
            print(f"   å»ºè®®: {rec['action']}")
            print(f"   é¢„æœŸæ•ˆæœ: {rec['expected_benefit']}")
            print()
        
        return recommendations
    
    def generate_optimized_config(self, config_path: str, recommendations: List[Dict], output_path: str):
        """ç”Ÿæˆä¼˜åŒ–åçš„é…ç½®æ–‡ä»¶"""
        print("=" * 80)
        print("ç”Ÿæˆä¼˜åŒ–é…ç½®".center(80))
        print("=" * 80)
        
        # åŠ è½½åŸå§‹é…ç½®
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)
        
        # åº”ç”¨é«˜ä¼˜å…ˆçº§å»ºè®®
        applied_changes = []
        for rec in recommendations:
            if rec['priority'] in ['CRITICAL', 'HIGH']:
                if 'config_change' in rec:
                    for section, changes in rec['config_change'].items():
                        if section not in config:
                            config[section] = {}
                        config[section].update(changes)
                    applied_changes.append(rec['title'])
        
        # ä¿å­˜ä¼˜åŒ–åçš„é…ç½®
        output_file = Path(output_path)
        with open(output_file, 'w') as f:
            yaml.dump(config, f, default_flow_style=False, sort_keys=False)
        
        print(f"\nâœ… å·²ç”Ÿæˆä¼˜åŒ–é…ç½®: {output_file}")
        print(f"\nå·²åº”ç”¨çš„ä¼˜åŒ–:")
        for change in applied_changes:
            print(f"  âœ“ {change}")
        
        print(f"\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
        print(f"  python src/train.py --config {output_file}")
        
        return output_file
    
    def analyze_training_log(self, log_file: Path):
        """åˆ†æè®­ç»ƒæ—¥å¿—ä¸­çš„æ€§èƒ½æ•°æ®"""
        print("\n" + "=" * 80)
        print("è®­ç»ƒæ—¥å¿—æ€§èƒ½åˆ†æ".center(80))
        print("=" * 80)
        
        if not log_file.exists():
            print(f"\nâš ï¸  æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file}")
            return
        
        print(f"\nğŸ“„ åˆ†ææ—¥å¿—æ–‡ä»¶: {log_file.name}\n")
        
        # è§£ææ—¥å¿—
        stage_times = defaultdict(list)
        fusion_times = defaultdict(list)
        forward_times = []
        
        with open(log_file, 'r', encoding='utf-8') as f:
            for line in f:
                # æå–æ€»å‰å‘ä¼ æ’­æ—¶é—´
                if match := re.search(r'å‰å‘ä¼ æ’­æ€»è€—æ—¶: ([\d.]+)ms', line):
                    forward_times.append(float(match.group(1)))
                
                # æå–å„Stageè€—æ—¶
                if match := re.search(r'\[VRT\] Stage (\d+).*?è€—æ—¶: ([\d.]+)ms', line):
                    stage_num = int(match.group(1))
                    time_ms = float(match.group(2))
                    stage_times[stage_num].append(time_ms)
                
                # æå–èåˆè€—æ—¶
                if match := re.search(r'\[VRTèåˆ\] Stage (\d+) æ€»è€—æ—¶: ([\d.]+)ms', line):
                    stage_num = int(match.group(1))
                    time_ms = float(match.group(2))
                    fusion_times[stage_num].append(time_ms)
        
        if not forward_times:
            print("âš ï¸  æ—¥å¿—ä¸­æœªæ‰¾åˆ°æ€§èƒ½è®¡æ—¶ä¿¡æ¯")
            print("   æç¤º: ç¡®ä¿è®­ç»ƒæ—¶å¼€å¯äº†timingè°ƒè¯•è¾“å‡º")
            return
        
        # æ€»ä½“æ€§èƒ½ç»Ÿè®¡
        print("ğŸ“Š æ€»ä½“æ€§èƒ½:")
        avg_forward = sum(forward_times) / len(forward_times)
        print(f"  å‰å‘ä¼ æ’­å¹³å‡è€—æ—¶: {avg_forward:.2f} ms")
        print(f"  æœ€å°/æœ€å¤§: {min(forward_times):.2f} / {max(forward_times):.2f} ms")
        print(f"  æ ·æœ¬æ•°: {len(forward_times)}")
        
        # å„Stageæ€§èƒ½åˆ†æ
        if stage_times:
            print("\nğŸ“Š VRTå„Stageæ€§èƒ½åˆ†æ:")
            print("-" * 80)
            
            stage_data = []
            for stage_num in sorted(stage_times.keys()):
                times = stage_times[stage_num]
                if times:
                    avg_time = sum(times) / len(times)
                    percentage = (avg_time / avg_forward) * 100
                    stage_data.append((stage_num, avg_time, percentage))
                    
                    stage_name = {
                        1: "Stage 1 (1xåˆ†è¾¨ç‡)",
                        2: "Stage 2 (1/2xåˆ†è¾¨ç‡)",
                        3: "Stage 3 (1/4xåˆ†è¾¨ç‡)",
                        4: "Stage 4 (1/8xåˆ†è¾¨ç‡)",
                        5: "Stage 5 (ç“¶é¢ˆå±‚)",
                        6: "Stage 6 (è§£ç 1/4x)",
                        7: "Stage 7 (è§£ç 1/2x)",
                        8: "Stage 8 (é‡å»ºå±‚)",
                    }.get(stage_num, f"Stage {stage_num}")
                    
                    # æ ¹æ®å æ¯”æ ‡è®°ä¼˜å…ˆçº§
                    if percentage > 15:
                        priority = "ğŸ”´ æé«˜"
                    elif percentage > 8:
                        priority = "ğŸŸ  é«˜"
                    elif percentage > 5:
                        priority = "ğŸŸ¡ ä¸­"
                    else:
                        priority = "âœ… ä½"
                    
                    print(f"\n  {stage_name}")
                    print(f"    å¹³å‡è€—æ—¶: {avg_time:.2f} ms ({percentage:.1f}%)")
                    print(f"    ä¼˜åŒ–ä¼˜å…ˆçº§: {priority}")
            
            # æ€§èƒ½ç“¶é¢ˆæ’å
            print("\n" + "-" * 80)
            print("ğŸ”¥ æ€§èƒ½ç“¶é¢ˆæ’å (Top 5):")
            stage_data.sort(key=lambda x: x[1], reverse=True)
            
            for rank, (stage_num, avg_time, percentage) in enumerate(stage_data[:5], 1):
                stage_name = {
                    1: "Stage 1 (1x)", 2: "Stage 2 (1/2x)", 3: "Stage 3 (1/4x)",
                    4: "Stage 4 (1/8x)", 5: "Stage 5 (ç“¶é¢ˆ)", 6: "Stage 6 (è§£ç 1/4x)",
                    7: "Stage 7 (è§£ç 1/2x)", 8: "Stage 8 (é‡å»º)",
                }.get(stage_num, f"Stage {stage_num}")
                
                print(f"  #{rank}. {stage_name}: {avg_time:.2f} ms ({percentage:.1f}%)")
            
            # ä¼˜åŒ–å»ºè®®
            print("\nğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
            if stage_data and stage_data[0][2] > 30:
                print(f"  â€¢ Stage {stage_data[0][0]} æ˜¯ä¸»è¦ç“¶é¢ˆï¼Œå ç”¨{stage_data[0][2]:.1f}%æ—¶é—´")
                print(f"    å»ºè®®ä¼˜å…ˆä¼˜åŒ–è¯¥é˜¶æ®µ")
            
            high_cost_stages = [s for s in stage_data if s[2] > 15]
            if len(high_cost_stages) >= 2:
                print(f"  â€¢ å‘ç°{len(high_cost_stages)}ä¸ªé«˜è€—æ—¶é˜¶æ®µ(>15%)")
                print(f"    å»ºè®®è€ƒè™‘æ¨¡å‹æ¶æ„ä¼˜åŒ–")
            
            print(f"  â€¢ é€šç”¨ä¼˜åŒ–:")
            print(f"    - å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ(AMP)")
            print(f"    - ä½¿ç”¨Flash Attention(å¦‚æœæ”¯æŒ)")
            print(f"    - å‡å°‘Transformerå—æ•°é‡")
    
    def estimate_training_speed(self, requirements: Dict):
        """ä¼°ç®—è®­ç»ƒé€Ÿåº¦"""
        print("\n" + "=" * 80)
        print("è®­ç»ƒé€Ÿåº¦é¢„ä¼°".center(80))
        print("=" * 80)
        
        if not self.benchmark_results:
            print("\nâš ï¸  æœªè¿è¡ŒåŸºå‡†æµ‹è¯•ï¼Œæ— æ³•ä¼°ç®—è®­ç»ƒé€Ÿåº¦")
            return
        
        # åŸºäºåŸºå‡†æµ‹è¯•ç»“æœä¼°ç®—
        avg_inference_ms = sum([r['inference_latency_ms'] for r in self.benchmark_results.values()]) / len(self.benchmark_results)
        
        # VRTæ¨¡å‹æ¯”ç®€å•CNNå¤æ‚çº¦30-50å€ï¼ˆç²—ç•¥ä¼°ç®—ï¼‰
        estimated_forward_ms = avg_inference_ms * 40
        
        # backward passçº¦ä¸ºforwardçš„2å€
        estimated_backward_ms = estimated_forward_ms * 2
        
        # æ¯ä¸ªè®­ç»ƒstepçš„æ€»æ—¶é—´
        step_time_ms = estimated_forward_ms + estimated_backward_ms
        
        # è€ƒè™‘æ¢¯åº¦ç´¯ç§¯
        effective_step_time_ms = step_time_ms * requirements['gradient_accum']
        
        # æ•°æ®åŠ è½½æ—¶é—´ï¼ˆå‡è®¾ä¸è®¡ç®—å¹¶è¡Œï¼Œå–è¾ƒå¤§å€¼ï¼‰
        data_loading_ms = 50  # å‡è®¾æ•°æ®åŠ è½½50ms
        
        total_step_time_s = max(effective_step_time_ms / 1000, data_loading_ms / 1000)
        
        steps_per_hour = 3600 / total_step_time_s
        
        print(f"\nâ±ï¸  é¢„ä¼°è®­ç»ƒé€Ÿåº¦:")
        print(f"  å•æ¬¡å‰å‘ä¼ æ’­: ~{estimated_forward_ms:.0f} ms")
        print(f"  å•æ¬¡åå‘ä¼ æ’­: ~{estimated_backward_ms:.0f} ms")
        print(f"  æ¯ä¸ªstep (å«æ¢¯åº¦ç´¯ç§¯): ~{total_step_time_s:.1f} s")
        print(f"  è®­ç»ƒé€Ÿåº¦: ~{steps_per_hour:.0f} steps/hour")
        
        # ä¼°ç®—å®Œæ•´è®­ç»ƒæ—¶é—´
        typical_steps = 300000  # å…¸å‹çš„æ€»è®­ç»ƒæ­¥æ•°
        estimated_hours = typical_steps / steps_per_hour
        estimated_days = estimated_hours / 24
        
        print(f"\nğŸ“… é¢„ä¼°å®Œæ•´è®­ç»ƒæ—¶é—´ ({typical_steps:,} steps):")
        print(f"  æ€»è®¡: {estimated_hours:.1f} å°æ—¶ ({estimated_days:.1f} å¤©)")
        
        print(f"\nğŸ’¡ åŠ é€Ÿå»ºè®®:")
        print(f"  â€¢ ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (AMP) å¯æé€Ÿ 20-30%")
        print(f"  â€¢ å¢å¤§batch sizeå¯æé«˜GPUåˆ©ç”¨ç‡")
        print(f"  â€¢ ä½¿ç”¨å¤šGPUå¯çº¿æ€§åŠ é€Ÿ")


def main():
    """ä¸»å‡½æ•°"""
    print("\n")
    print("=" * 80)
    print("ç¡¬ä»¶èµ„æºä¸è®­ç»ƒé€Ÿåº¦åˆ†æå·¥å…·".center(80))
    print("=" * 80)
    print("\næœ¬å·¥å…·å°†å¸®åŠ©ä½ :")
    print("  1. æ£€æµ‹ç³»ç»Ÿç¡¬ä»¶èµ„æº")
    print("  2. åˆ†æGPUæ˜¾å­˜ä½¿ç”¨æƒ…å†µ")
    print("  3. è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("  4. åˆ†æè®­ç»ƒé…ç½®çš„å¯è¡Œæ€§")
    print("  5. åˆ†æè®­ç»ƒæ—¥å¿—æ€§èƒ½(å¯é€‰)")
    print("  6. ç”Ÿæˆä¼˜åŒ–å»ºè®®å’Œæ¨èé…ç½®")
    print("\n")
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    import argparse
    parser = argparse.ArgumentParser(description='ç¡¬ä»¶èµ„æºä¸è®­ç»ƒé€Ÿåº¦åˆ†æå·¥å…·')
    parser.add_argument('--config', type=str, default='configs/deblur/vrt_spike_baseline.yaml',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--log', type=str, default=None,
                       help='è®­ç»ƒæ—¥å¿—æ–‡ä»¶è·¯å¾„(å¯é€‰ï¼Œç”¨äºæ€§èƒ½åˆ†æ)')
    parser.add_argument('--auto', action='store_true',
                       help='è‡ªåŠ¨æ¨¡å¼ï¼šè·³è¿‡æ‰€æœ‰äº¤äº’å¼è¯¢é—®')
    
    # å…¼å®¹æ—§çš„å‘½ä»¤è¡Œæ–¹å¼
    if len(sys.argv) > 1 and not sys.argv[1].startswith('--'):
        args = argparse.Namespace(config=sys.argv[1], log=None, auto=False)
    else:
        args = parser.parse_args()
    
    # å¤„ç†é…ç½®æ–‡ä»¶è·¯å¾„
    config_path = Path(args.config)
    if not config_path.is_absolute():
        config_path = REPO_ROOT / config_path
    
    if not config_path.exists():
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        print(f"\nç”¨æ³•: python {Path(__file__).name} [--config CONFIG] [--log LOG] [--auto]")
        print(f"ç¤ºä¾‹: python {Path(__file__).name} --config configs/deblur/vrt_spike_baseline.yaml")
        return
    
    print(f"ğŸ“„ åˆ†æé…ç½®æ–‡ä»¶: {config_path.relative_to(REPO_ROOT)}\n")
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = HardwareAnalyzer()
    
    # 1. æ£€æµ‹ç¡¬ä»¶
    if not analyzer.detect_hardware():
        print("\nâŒ ç¡¬ä»¶æ£€æµ‹å¤±è´¥ï¼Œè¯·ç¡®ä¿ç³»ç»Ÿæœ‰å¯ç”¨çš„GPU")
        return
    
    # 2. GPUæ˜¾å­˜è¯¦ç»†åˆ†æ
    if args.auto:
        run_memory_analysis = True
    else:
        run_memory_analysis = input("\næ˜¯å¦è¿è¡ŒGPUæ˜¾å­˜è¯¦ç»†åˆ†æ? [Y/n]: ").strip().lower() != 'n'
    
    if run_memory_analysis:
        analyzer.analyze_gpu_memory_details()
    
    # 3. è¿è¡ŒåŸºå‡†æµ‹è¯•
    if args.auto:
        run_benchmark = True
    else:
        run_benchmark = input("\næ˜¯å¦è¿è¡ŒGPUåŸºå‡†æµ‹è¯•? (çº¦30ç§’) [Y/n]: ").strip().lower() != 'n'
    
    if run_benchmark:
        analyzer.run_gpu_benchmark()
    
    # 4. åˆ†æè®­ç»ƒéœ€æ±‚
    requirements = analyzer.estimate_training_requirements(str(config_path))
    
    # 5. ç”Ÿæˆå»ºè®®
    recommendations = analyzer.generate_recommendations(requirements)
    
    # 6. ä¼°ç®—è®­ç»ƒé€Ÿåº¦
    if run_benchmark:
        analyzer.estimate_training_speed(requirements)
    
    # 7. åˆ†æè®­ç»ƒæ—¥å¿—(å¦‚æœæä¾›)
    if args.log:
        log_path = Path(args.log)
        if not log_path.is_absolute():
            log_path = REPO_ROOT / log_path
        analyzer.analyze_training_log(log_path)
    else:
        # å°è¯•è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„è®­ç»ƒæ—¥å¿—
        log_dir = REPO_ROOT / "outputs" / "logs"
        if log_dir.exists():
            log_files = sorted(log_dir.glob("train_*.log"), 
                             key=lambda p: p.stat().st_mtime, reverse=True)
            if log_files:
                if args.auto:
                    analyze_log = True
                else:
                    analyze_log = input(f"\nå‘ç°è®­ç»ƒæ—¥å¿— {log_files[0].name}ï¼Œæ˜¯å¦åˆ†æ? [y/N]: ").strip().lower() == 'y'
                
                if analyze_log:
                    analyzer.analyze_training_log(log_files[0])
    
    # 8. ç”Ÿæˆä¼˜åŒ–é…ç½®
    if recommendations:
        if args.auto:
            generate_config = True
        else:
            generate_config = input("\næ˜¯å¦ç”Ÿæˆä¼˜åŒ–åçš„é…ç½®æ–‡ä»¶? [Y/n]: ").strip().lower() != 'n'
        
        if generate_config:
            output_name = config_path.stem + "_optimized.yaml"
            output_path = config_path.parent / output_name
            analyzer.generate_optimized_config(
                str(config_path),
                recommendations,
                str(output_path)
            )
    
    # æ€»ç»“
    print("\n" + "=" * 80)
    print("åˆ†æå®Œæˆ".center(80))
    print("=" * 80)
    print("\nğŸ“ ä¸‹ä¸€æ­¥:")
    print("  1. æŸ¥çœ‹ä¸Šè¿°ä¼˜åŒ–å»ºè®®")
    print("  2. æ ¹æ®å»ºè®®ä¿®æ”¹é…ç½®æ–‡ä»¶")
    print("  3. è¿è¡Œè®­ç»ƒå‰æµ‹è¯•: python tests/integration/training/test_system_readiness.py")
    print("  4. å¼€å§‹è®­ç»ƒ: python src/train.py --config <your_config>.yaml")
    print("\nğŸ’¡ æç¤º:")
    print("  â€¢ é¦–æ¬¡è®­ç»ƒå»ºè®®ä½¿ç”¨è¾ƒå°çš„batch sizeå’Œè¾ƒçŸ­çš„éªŒè¯é—´éš”")
    print("  â€¢ è®­ç»ƒè¿‡ç¨‹ä¸­å¯ä½¿ç”¨ nvidia-smi ç›‘æ§GPUä½¿ç”¨æƒ…å†µ")
    print("  â€¢ é‡åˆ°OOMé”™è¯¯æ—¶ï¼Œå°è¯•å‡å°batch sizeæˆ–å¯ç”¨gradient checkpointing")
    print("  â€¢ å¯ä»¥ä½¿ç”¨ --auto å‚æ•°è¿è¡Œè‡ªåŠ¨æ¨¡å¼ï¼Œè·³è¿‡æ‰€æœ‰è¯¢é—®")
    print("\n")


if __name__ == "__main__":
    main()

